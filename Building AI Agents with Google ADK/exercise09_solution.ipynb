{"cells":[{"source":"# It takes a village: Multi-agent customer support","metadata":{},"id":"ae70f448-f79e-416c-9bfa-ee7800531a12","cell_type":"markdown"},{"source":"### ðŸŒ Creating a Root Agent with Sub-Agents \n\nWith multi-agents, each agent can specialize in a certain role, with a coordinator delegating tasks to the appropriate specialist. \n\nIn our customer support example, imagine we want a more robust support assistant. We could break it into:\n\n- ðŸ‘‹ A **Greeting Agent**, handling greetings.\n- ðŸ”‘ An **Account Agent**, handling account access issues.\n- â“ An **FAQ Agent**, using a pre-defined list of FAQs to answer common customer questions.\n- ðŸ§­ A **Root Agent (Coordinator)** that receives the userâ€™s query and decides which of the other agents should handle it, or handles it itself if it doesnâ€™t fit any specialized category.","metadata":{},"id":"73104146-82e2-4635-b958-0f3db0d9ccfc","cell_type":"markdown"},{"source":"## â—ï¸ Note: Run the **hidden cells** below to initialize the agent, before running the rest of the code. â—ï¸ ","metadata":{},"id":"eef0d070-8aba-44b4-9e1e-7449ae9975a1","cell_type":"markdown"},{"source":"!pip install protobuf==5.28.1 google-adk==1.0.0 litellm -q -q","metadata":{"executionCancelledAt":null,"executionTime":3524,"lastExecutedAt":1750855094320,"lastExecutedByKernel":"524bdb6c-b942-4376-ba41-ea5d71c9ec3e","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"!pip install protobuf==5.28.1 google-adk==1.0.0 litellm -q -q","collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":true},"outputsMetadata":{"0":{"height":248,"type":"stream"}}},"id":"8e135708-98c1-4e12-9b17-4891c177d8c9","cell_type":"code","execution_count":1,"outputs":[]},{"source":"import importlib\nimportlib.invalidate_caches()","metadata":{"executionCancelledAt":null,"executionTime":886,"lastExecutedAt":1750855095208,"lastExecutedByKernel":"524bdb6c-b942-4376-ba41-ea5d71c9ec3e","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import importlib\nimportlib.invalidate_caches()","collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":true}},"id":"cf9ba90f-a906-4fe5-9ba9-1500c665c9f0","cell_type":"code","execution_count":2,"outputs":[]},{"source":"import os\nfrom google.adk.agents import LlmAgent\nfrom google.adk.tools import FunctionTool\nfrom google import genai\nfrom google.adk.models.lite_llm import LiteLlm\nimport litellm\nimport os\n\nos.environ[\"OPENAI_API_BASE\"]=\"http://localhost:11434/v1\"\n\nAGENT_MODEL = LiteLlm(model=\"openai/gpt-4o-mini\")","metadata":{"executionCancelledAt":null,"executionTime":9314,"lastExecutedAt":1750855104522,"lastExecutedByKernel":"524bdb6c-b942-4376-ba41-ea5d71c9ec3e","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import os\nfrom google.adk.agents import LlmAgent\nfrom google.adk.tools import FunctionTool\nfrom google import genai\nfrom google.adk.models.lite_llm import LiteLlm\nimport litellm\nimport os\n\nos.environ[\"OPENAI_API_BASE\"]=\"http://localhost:11434/v1\"\n\nAGENT_MODEL = LiteLlm(model=\"openai/gpt-4o-mini\")","collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":true}},"id":"86663ea1-9f31-42dd-8ffa-60748cce7526","cell_type":"code","execution_count":3,"outputs":[]},{"source":"# Install and import required libraries\nimport nest_asyncio\nimport asyncio\nnest_asyncio.apply()  # Required for async in notebooks\n\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.genai import types\n\n# Constants â€” define application, user, and session identifiers\nAPP_NAME      = \"adk_course_app\"\nUSER_ID       = \"user_123\"\nSESSION_ID    = \"support_session\"","metadata":{"executionCancelledAt":null,"executionTime":54,"lastExecutedAt":1750855104577,"lastExecutedByKernel":"524bdb6c-b942-4376-ba41-ea5d71c9ec3e","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Install and import required libraries\nimport nest_asyncio\nimport asyncio\nnest_asyncio.apply()  # Required for async in notebooks\n\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.genai import types\n\n# Constants â€” define application, user, and session identifiers\nAPP_NAME      = \"adk_course_app\"\nUSER_ID       = \"user_123\"\nSESSION_ID    = \"support_session\""},"id":"f9cc29f4-3689-4c35-a146-dd31a88088c2","cell_type":"code","execution_count":4,"outputs":[]},{"source":"# FAQ knowledge base & tool \nFAQ_DATA = {\n    \"return policy\": \"You can return items within 30 days of purchase.\",\n    \"hours\": \"Our support team is available from 9 am to 5 pm, Monday to Friday.\",\n    \"contact\": \"You can reach support at help@example.com.\"\n}\n\ndef lookup_faq(question: str) -> str:\n    faq_text = \"\\n\".join(f\"- {k}: {v}\" for k, v in FAQ_DATA.items())\n    prompt = (\n        f\"You are a helpful assistant. Here is a list of FAQs:\\n\\n{faq_text}\\n\\n\"\n        f\"User question: \\\"{question}\\\". \"\n        f\"Reply with the best match or say you don't know.\"\n    )\n    response = litellm.completion(\n        model=\"gpt-4o-mini\",\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    return response[\"choices\"][0][\"message\"][\"content\"].strip()\n\nfaq_tool  = FunctionTool(func=lookup_faq)","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1750855104629,"lastExecutedByKernel":"524bdb6c-b942-4376-ba41-ea5d71c9ec3e","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# FAQ knowledge base & tool \nFAQ_DATA = {\n    \"return policy\": \"You can return items within 30 days of purchase.\",\n    \"hours\": \"Our support team is available from 9 am to 5 pm, Monday to Friday.\",\n    \"contact\": \"You can reach support at help@example.com.\"\n}\n\ndef lookup_faq(question: str) -> str:\n    faq_text = \"\\n\".join(f\"- {k}: {v}\" for k, v in FAQ_DATA.items())\n    prompt = (\n        f\"You are a helpful assistant. Here is a list of FAQs:\\n\\n{faq_text}\\n\\n\"\n        f\"User question: \\\"{question}\\\". \"\n        f\"Reply with the best match or say you don't know.\"\n    )\n    response = litellm.completion(\n        model=\"gpt-4o-mini\",\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    return response[\"choices\"][0][\"message\"][\"content\"].strip()\n\nfaq_tool  = FunctionTool(func=lookup_faq)"},"id":"e95adf8e-8cde-4cbb-8a1e-56bfd9bf0c0d","cell_type":"code","execution_count":5,"outputs":[]},{"source":"# Specialist Agents\ngreeting_agent = LlmAgent(\n    name=\"GreetingAgent\",\n    description=\"Handles greetings from users.\",\n    instruction=\"Respond cheerfully when the user says hello.\",\n    model=AGENT_MODEL\n)\n\naccount_agent = LlmAgent(\n    name=\"AccountAgent\",\n    description=\"Handles questions about login issues or account access.\",\n    instruction=\"Help users who are having trouble logging in or accessing their account.\",\n    model=AGENT_MODEL\n)\n\nfaq_agent = LlmAgent(\n    name=\"FAQAgent\",\n    description=\"Answers common questions using the FAQ knowledge base.\",\n    instruction=\"Use the FAQ tool to answer questions that match the FAQs.\",\n    model=AGENT_MODEL,\n    tools=[faq_tool]\n)\n\n# Root agent with delegation logic\nroot_agent = LlmAgent(\n    name=\"SupportRootAgent\",\n    description=\"Delegates to specialized sub-agents for support queries.\",\n    instruction=(\n        \"If the user greets you, delegate to GreetingAgent.\\n\"\n        \"If the user has an account or login issue, delegate to AccountAgent.\\n\"\n        \"If the question matches a known FAQ topic (e.g., returns, hours, contact), \"\n        \"delegate to FAQAgent. Do not answer as the FAQAgent if the topic doesn't match any of the FAQs.\\n\"\n        \"Otherwise, answer directly as best you (the Root Agent) can.\"\n    ),\n    model=AGENT_MODEL,\n    sub_agents=[greeting_agent, account_agent, faq_agent]\n)","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1750855104681,"lastExecutedByKernel":"524bdb6c-b942-4376-ba41-ea5d71c9ec3e","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Specialist agents \ngreeting_agent = LlmAgent(\n    name         = \"GreetingAgent\",\n    description  = \"Handles greetings from users.\",\n    instruction  = \"Respond cheerfully when the user says hello.\",\n    model        = AGENT_MODEL\n)\n\naccount_agent = LlmAgent(\n    name         = \"AccountAgent\",\n    description  = \"Handles questions about login issues or account access.\",\n    instruction  = \"Help users who are having trouble logging in or accessing their account.\",\n    model        = AGENT_MODEL\n)\n\nfaq_agent = LlmAgent(\n    name         = \"FAQAgent\",\n    description  = \"Answers common questions using the FAQ knowledge base.\",\n    instruction  = \"Use the FAQ tool to answer questions that match the FAQs.\",\n    model        = AGENT_MODEL,\n    tools        = [faq_tool]\n)\n\n# Root agent with delegation logic \nroot_agent = LlmAgent(\n    name         = \"SupportRootAgent\",\n    description  = \"Delegates to specialized sub-agents for support queries.\",\n    instruction  = (\n        \"If the user greets you, delegate to GreetingAgent.\\n\"\n        \"If the user has an account or login issue, delegate to AccountAgent.\\n\"\n        \"If the question matches a known FAQ topic (e.g., return policy, hours, contact), \"\n        \"delegate to FAQAgent. \\n\"\n        \"Otherwise, answer directly as best you (the Root Agent) can.\"\n    ),\n    model        = AGENT_MODEL,\n    sub_agents   = [greeting_agent, account_agent, faq_agent]\n)"},"id":"b38c8a85-0457-49bb-9a71-383d98316334","cell_type":"code","execution_count":6,"outputs":[]},{"source":"# Session & runner \nsession_service = InMemorySessionService()\nawait session_service.create_session(app_name=APP_NAME, user_id=USER_ID,\n                               session_id=SESSION_ID)\n\nrunner = Runner(agent=root_agent, app_name=APP_NAME, session_service=session_service)\n\n# Function to chat with the root agent\nasync def call_agent_async(query: str):\n    print(f\"\\n>>> User Query: {query}\")\n    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n    final_response = \"Agent did not produce a final response.\"\n\n    async for event in runner.run_async(user_id=USER_ID,\n                                        session_id=SESSION_ID,\n                                        new_message=content):\n        if event.is_final_response():\n            if event.content and event.content.parts:\n                final_response = event.content.parts[0].text\n            break\n\n    print(f\"<<< Agent {event.author}'s response: {final_response}\")\n\n# Test the full system\nawait call_agent_async(\"Hello!\")                       # GreetingAgent\nawait call_agent_async(\"I can't access my account.\")   # AccountAgent\nawait call_agent_async(\"What is your return policy?\")  # FAQAgent\nawait call_agent_async(\"I have a privacy question.\")   # SupportRootAgent","metadata":{"executionCancelledAt":null,"executionTime":10651,"lastExecutedAt":1750855115332,"lastExecutedByKernel":"524bdb6c-b942-4376-ba41-ea5d71c9ec3e","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Session & runner \nsession_service = InMemorySessionService()\nawait session_service.create_session(app_name=APP_NAME, user_id=USER_ID,\n                               session_id=SESSION_ID)\n\nrunner = Runner(agent=root_agent, app_name=APP_NAME, session_service=session_service)\n\n# Function to chat with the root agent\nasync def call_agent_async(query: str):\n    print(f\"\\n>>> User Query: {query}\")\n    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n    final_response = \"Agent did not produce a final response.\"\n\n    async for event in runner.run_async(user_id=USER_ID,\n                                        session_id=SESSION_ID,\n                                        new_message=content):\n        if event.is_final_response():\n            if event.content and event.content.parts:\n                final_response = event.content.parts[0].text\n            break\n\n    print(f\"<<< Agent {event.author}'s response: {final_response}\")\n\n# Test the full system\nawait call_agent_async(\"Hello!\")                       # GreetingAgent\nawait call_agent_async(\"I can't access my account.\")   # AccountAgent\nawait call_agent_async(\"What is your return policy?\")  # FAQAgent\nawait call_agent_async(\"I have a privacy question.\")   # SupportRootAgent","outputsMetadata":{"0":{"height":353,"type":"stream"}}},"id":"f0d24b50-1873-47f0-af18-39ae54ce4d9f","cell_type":"code","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":"\n>>> User Query: Hello!\n<<< Agent GreetingAgent's response: Hello there! ðŸ˜Š How can I assist you today?\n\n>>> User Query: I can't access my account.\n<<< Agent AccountAgent's response: I'm here to help you with your account access issue. Can you please provide more details about the problem you're experiencing? Are you receiving an error message, or is there something specific hindering your access?\n\n>>> User Query: What is your return policy?\n<<< Agent FAQAgent's response: Our return policy allows you to return items within 30 days of purchase.\n\n>>> User Query: I have a privacy question.\n<<< Agent SupportRootAgent's response: You can provide your privacy question, and I will do my best to answer it!\n"}]},{"source":"After running the queries, we can observe how our agents collaborated to best address the queries. We have now built a mini multi-agent system using Google ADK! ðŸŽ‰","metadata":{},"id":"b4bd4a13-7f70-4c6c-8eb6-e2916c827aae","cell_type":"markdown"}],"metadata":{"language_info":{"name":"python","version":"3.12.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (User venv)","language":"python","name":"python3"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}